{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils import standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "train_X = torch.rand(10, 2, dtype=torch.float64)\n",
    "Y = 1 - torch.linalg.norm(train_X - 0.5, dim=-1, keepdim=True)\n",
    "Y = Y + 0.1 * torch.randn_like(Y)  # add some noise\n",
    "train_Y = standardize(Y)\n",
    "\n",
    "gp = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_mll(mll)\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7960, 0.0438],\n",
       "        [0.9746, 0.4776],\n",
       "        [0.9788, 0.6750],\n",
       "        [0.4715, 0.0878],\n",
       "        [0.6946, 0.3246],\n",
       "        [0.2092, 0.1813],\n",
       "        [0.7608, 0.8820],\n",
       "        [0.9150, 0.6585],\n",
       "        [0.7536, 0.2738],\n",
       "        [0.5355, 0.6539]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import qExpectedImprovement, qMaxValueEntropy\n",
    "\n",
    "\n",
    "\n",
    "qEI = qExpectedImprovement(gp,train_Y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4028, 0.6002]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "bounds = torch.stack([torch.zeros(2), torch.ones(2)])\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    qEI,\n",
    "    bounds=bounds,\n",
    "    q=1,\n",
    "    num_restarts=5,\n",
    "    raw_samples=20,\n",
    ")\n",
    "candidate  # tensor([0.4887, 0.5063])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional, Type, Callable, Tuple\n",
    "from inspect import signature\n",
    "from botorch.acquisition import AcquisitionFunction\n",
    "from botorch.acquisition.objective import PosteriorTransform\n",
    "from botorch.models.gpytorch import Model\n",
    "from botorch.posteriors import Posterior\n",
    "from botorch.posteriors.gpytorch import GPyTorchPosterior\n",
    "from torch import Tensor\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "class SklearnSurrogate(Model):\n",
    "    # Partially copied from BayBe https://github.com/emdgroup/baybe\n",
    "    def __init__(self, surrogate) -> None:\n",
    "        super().__init__()\n",
    "        self._surrogate = surrogate\n",
    "\n",
    "    @property\n",
    "    def num_outputs(self) -> int:\n",
    "        return 1\n",
    "\n",
    "    def posterior(\n",
    "        self,\n",
    "        X: Tensor,\n",
    "        output_indices: Optional[List[int]] = None,\n",
    "        observation_noise: bool = False,\n",
    "        posterior_transform: Optional[Callable[[Posterior], Posterior]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Posterior:\n",
    "        \n",
    "        x = X.to(torch.float64)\n",
    "        \n",
    "        t_shape = x.shape[:-2]\n",
    "        q_shape = x.shape[-2]\n",
    "        x_fl = x.flatten(end_dim=-2)\n",
    "\n",
    "        _mu, _si = self._surrogate.predict(x_fl.numpy(),return_std=True)\n",
    "        \n",
    "        mu = torch.from_numpy(_mu)\n",
    "        si = torch.from_numpy(_si).pow(2)\n",
    "        \n",
    "        q_mu = torch.reshape(mu, t_shape + (q_shape,))\n",
    "        q_si = torch.reshape(si, t_shape + (q_shape,))\n",
    "\n",
    "        cova = torch.diag_embed(q_si)\n",
    "        cova.add_(torch.eye(cova.shape[-1]) * 1e-9)\n",
    "        \n",
    "        dist = MultivariateNormal(q_mu, cova)\n",
    "        \n",
    "        return(GPyTorchPosterior(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3000, 0.3000],\n",
       "         [0.2000, 0.2000]]),\n",
       " tensor([0.0077, 0.0145], dtype=torch.float64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "from botorch.optim import optimize_acqf_discrete\n",
    "\n",
    "brr = BayesianRidge().fit(train_X, train_Y.ravel())\n",
    "\n",
    "bo_brr = SklearnSurrogate(brr)\n",
    "\n",
    "qEI = qExpectedImprovement(bo_brr,train_Y.max())\n",
    "\n",
    "acqf = optimize_acqf_discrete(\n",
    "    qEI,\n",
    "    q=2,\n",
    "    choices=torch.Tensor([[.1,.1],[.2,.2],[.3,.3]]),\n",
    ")\n",
    "acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForestSurrogate(Model):\n",
    "    # Partially copied from BayBe https://github.com/emdgroup/baybe\n",
    "    def __init__(self, surrogate) -> None:\n",
    "        super().__init__()\n",
    "        self._surrogate = surrogate\n",
    "\n",
    "    @property\n",
    "    def num_outputs(self) -> int:\n",
    "        return 1\n",
    "\n",
    "    def posterior(\n",
    "        self,\n",
    "        X: Tensor,\n",
    "        output_indices: Optional[List[int]] = None,\n",
    "        observation_noise: bool = False,\n",
    "        posterior_transform: Optional[Callable[[Posterior], Posterior]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Posterior:\n",
    "        \n",
    "        x = X.to(torch.float64)\n",
    "        \n",
    "        t_shape = x.shape[:-2]\n",
    "        q_shape = x.shape[-2]\n",
    "        x_fl = x.flatten(end_dim=-2)\n",
    "\n",
    "        preds = np.array([self._surrogate.estimators_[tree].predict(x_fl) for tree in range(self._surrogate.n_estimators)])\n",
    "\n",
    "        _mu, _si = preds.mean(0), preds.std(0)\n",
    "        \n",
    "        mu = torch.from_numpy(_mu)\n",
    "        si = torch.from_numpy(_si).pow(2)\n",
    "        \n",
    "        q_mu = torch.reshape(mu, t_shape + (q_shape,))\n",
    "        q_si = torch.reshape(si, t_shape + (q_shape,))\n",
    "\n",
    "        cova = torch.diag_embed(q_si)\n",
    "        cova.add_(torch.eye(cova.shape[-1]) * 1e-9)\n",
    "        \n",
    "        dist = MultivariateNormal(q_mu, cova)\n",
    "        \n",
    "        return(GPyTorchPosterior(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3000, 0.3000],\n",
       "         [0.2000, 0.2000]]),\n",
       " tensor([0.0369, 0.0403], dtype=torch.float64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor().fit(train_X, train_Y.ravel())\n",
    "\n",
    "bo_rf = ForestSurrogate(rf)\n",
    "\n",
    "qEI = qExpectedImprovement(bo_rf,train_Y.max())\n",
    "\n",
    "acqf = optimize_acqf_discrete(\n",
    "    qEI,\n",
    "    q=2,\n",
    "    choices=,\n",
    ")\n",
    "acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._bayes.BayesianRidge"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(brr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ForestSurrogate' object has no attribute 'fantasize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m cands \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([[\u001b[38;5;241m.1\u001b[39m,\u001b[38;5;241m.1\u001b[39m],[\u001b[38;5;241m.2\u001b[39m,\u001b[38;5;241m.2\u001b[39m],[\u001b[38;5;241m.3\u001b[39m,\u001b[38;5;241m.3\u001b[39m]])\n\u001b[1;32m      3\u001b[0m qMES \u001b[38;5;241m=\u001b[39m qMaxValueEntropy(bo_rf, cands)\n\u001b[0;32m----> 5\u001b[0m acqf \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf_discrete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqMES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchoices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m acqf\n",
      "File \u001b[0;32m~/miniconda3/envs/roa/lib/python3.9/site-packages/botorch/optim/optimize.py:1045\u001b[0m, in \u001b[0;36moptimize_acqf_discrete\u001b[0;34m(acq_function, q, choices, max_batch_size, unique, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# set pending points\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m candidates \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(candidate_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 1045\u001b[0m \u001b[43macq_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_X_pending\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbase_X_pending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbase_X_pending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# need to remove choice from choice set if enforcing uniqueness\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique:\n",
      "File \u001b[0;32m~/miniconda3/envs/roa/lib/python3.9/site-packages/botorch/acquisition/max_value_entropy_search.py:391\u001b[0m, in \u001b[0;36mqMaxValueEntropy.set_X_pending\u001b[0;34m(self, X_pending)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# fantasize the model and use this as the new model\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfantasize\u001b[49m(\n\u001b[1;32m    392\u001b[0m         X\u001b[38;5;241m=\u001b[39mX_pending,\n\u001b[1;32m    393\u001b[0m         sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfantasies_sampler,\n\u001b[1;32m    394\u001b[0m     )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m init_model\n",
      "File \u001b[0;32m~/miniconda3/envs/roa/lib/python3.9/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ForestSurrogate' object has no attribute 'fantasize'"
     ]
    }
   ],
   "source": [
    "cands = torch.Tensor([[.1,.1],[.2,.2],[.3,.3]])\n",
    "\n",
    "qMES = qMaxValueEntropy(bo_rf, cands)\n",
    "\n",
    "acqf = optimize_acqf_discrete(\n",
    "    qMES,\n",
    "    q=2,\n",
    "    choices=cands,\n",
    ")\n",
    "acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
